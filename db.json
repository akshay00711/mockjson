{
  "posts": [
    { "id": 1, "title": "Post 1" },
    { "id": 2, "title": "Post 2" },
    { "id": 3, "title": "Post 3" }
  ],
  "comments": [
    { "id": 1, "body": "some comment", "postId": 1 },
    { "id": 2, "body": "some comment", "postId": 1 }
  ],
  "profile": {
    "name": "typicode"
  },
  "allPost" : [{"slug":"sora-ai","title":"Creating video from text","date":"2023-10-16","image":"sora-ai.png","excerpt":"Sora can generate videos up to a minute long while maintaining visual quality and adherence to the user’s prompt.","isFeatured":false,"readerCount":"1.2k","content":"\r\n Sora is an AI model that can create realistic and imaginative scenes from text instructions.\r\n \r\n Today, Sora is becoming available to red teamers to assess critical areas for harms or risks.\r\n  \r\n We are also granting access to a number of visual artists, designers, and filmmakers to gain feedback on how to advance the model to be most helpful for creative professionals.\r\n \r\n We’re sharing our research progress early to start working with and getting feedback from people outside of OpenAI and to give the public a sense of what AI capabilities are on the horizon.\r\n \r\n ## Safety\r\n \r\n  We’ll be taking several important safety steps ahead of making Sora available in OpenAI’s products.\r\n \r\n"},{"slug":"chat-gpt","title":"Open AI Chat GPT","excerpt":"ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot developed by OpenAI and launched on November 30, 2022. ","image":"chat-gpt.png","isFeatured":true,"readerCount":"3.2k","date":"2022-12-30","content":"\r\n       • Model Description: Large-scale language model capable of generating human-like text.\r\n       •	Model Category: Natural Language Processing (NLP)\r\n       •	Model Developer/Organization: OpenAI\r\n       •	Model Architecture: Transformer\r\n       •	Key Features: Natural language generation, text completion, language translation.\r\n       •	Performance Metrics: Achieved state-of-the-art performance on various language tasks.\r\n       •	Availability: Proprietary (API access provided by OpenAI)\r\n \r\n       Wikipedia link: https://en.wikipedia.org/wiki/GPT-3\r\n       Open AI’s blog link: https://openai.com/blog/gpt-3-apps\r\n       \r\n \r\n"},{"slug":"BERT","title":"Bidirectional Encoder Representations from Transformers","excerpt":"Pre-trained contextual language representation model developed by Google AI Language Team","image":"BERT.png","isFeatured":true,"readerCount":"2.4k","date":"2022-12-30","content":"\r\n        • Model Description: Pre-trained contextual language representation model. \r\n       •	Model Category: Natural Language Processing (NLP)\r\n       •	Model Developer/Organization: Google AI Language Team\r\n       •	Model Architecture: Transformer\r\n       •	Key Features: Contextual understanding of language, used for tasks like text classification, question answering, and more.\r\n       •	Performance Metrics: State-of-the-art results in various NLP benchmarks.\r\n       •	Availability: Open-source (licensed under Apache License 2.0)\r\n\n       Wikipedia link: https://en.wikipedia.org/wiki/BERT_(language_model)\r\n       Google’s official research blog: http://blog.research.google/2018/11/open-sourcing-bert-state-of-art-pre.html       \r\n \r\n"},{"slug":"YOLO","title":"You Only Look Once","excerpt":"Real-time object detection system developed by Joseph Redmon and Ali Farhadi","image":"YOLO.png","isFeatured":true,"readerCount":"2.7k","date":"2022-12-30","content":"\r\n•	Model Description: Real-time object detection system. \r\n       •	Model Category: Computer Vision\r\n       •	Model Developer/Organization: Joseph Redmon and Ali Farhadi\r\n       •	Model Architecture: Convolutional Neural Network (CNN)\r\n       •	Key Features: Fast object detection in real-time video streams.\r\n       •	Performance Metrics: High accuracy and speed compared to traditional object detection systems.\r\n       •	Availability: Open-source (licensed under MIT License)\r\n       v7 labs link: https://www.v7labs.com/blog/yolo-object-detection\r\n       Joseph Redmon official documentation: https://pjreddie.com/yolo/       \r\n \r\n"},{"slug":"ResNet","title":"Residual Neural Network","excerpt":"Deep convolutional neural network architecture developed by Microsoft Research","image":"ResNet.png","isFeatured":true,"readerCount":"1.7k","date":"2022-12-30","content":"\r\n         •	Model Description: Deep convolutional neural network architecture.         •	Model Category: Computer Vision         •	Model Developer/Organization: Microsoft Research         •	Model Architecture: Convolutional Neural Network (CNN)         •	Key Features: Very deep network architecture with skip connections to address the vanishing gradient problem.         •	Performance Metrics: Achieved state-of-the-art results in image classification tasks.         •	Availability: Open-source (licensed under MIT License)         Wikipedia link: https://en.wikipedia.org/wiki/Residual_neural_network         Microsoft official blog: https://www.microsoft.com/en-us/research/blog/microsoft-vision-model-resnet-50-combines-web-scale-data-and-multi-task-learning-to-achieve-state-of-the-art/         \r\n \r\n"},{"slug":"Transformer-XL","title":"Enhanced Transformer architecture for long-range dependencies","excerpt":"Developed by Google AI Language Team","image":"Transformer-XL.png","isFeatured":true,"readerCount":"3.7k","date":"2022-12-30","content":"\r\n         •	Model Description: Enhanced Transformer architecture for long-range dependencies.         •	Model Category: Natural Language Processing (NLP)         •	Model Developer/Organization: Google AI Language Team         •	Model Architecture: Transformer         •	Key Features: Improved modeling of long-range dependencies in sequences.         •	Performance Metrics: State-of-the-art results in various NLP tasks, especially for longer sequences.         •	Availability: Open-source (licensed under Apache License 2.0)         Github document: https://github.com/kimiyoung/transformer-xl         Google research blog: https://blog.research.google/2019/01/transformer-xl-unleashing-potential-of.html         \r\n \r\n"},{"slug":"ALBERT","title":"A Lite BERT","excerpt":"A lite version of BERT for efficient training and inference developed by Google Research Team","image":"ALBERT.png","isFeatured":false,"readerCount":"1.5k","date":"2022-12-30","content":"\r\n         •	Model Description: A lite version of BERT for efficient training and inference.         •	Model Category: Natural Language Processing (NLP)         •	Model Developer/Organization: Google Research         •	Model Architecture: Transformer         •	Key Features: Reduced model size and computational cost while maintaining performance.         •	Performance Metrics: Competitive performance compared to BERT with reduced parameters.         •	Availability: Open-source (licensed under Apache License 2.0)         Geeksforgeeks: https://paperswithcode.com/paper/albert-a-lite-bert-for-self-supervised         Google research blog: http://blog.research.google/2019/12/albert-lite-bert-for-self-supervised.html         \r\n \r\n"},{"slug":"EfficientNet","title":"Scalable and efficient Convolutional Neural Network (CNN) architecture.","excerpt":"Computer Vision Model developed by Google Research Team","image":"EfficientNet.png","isFeatured":true,"readerCount":"2.5k","date":"2022-12-30","content":"\r\n         •	Model Description: Scalable and efficient Convolutional Neural Network (CNN) architecture.         •	Model Category: Computer Vision         •	Model Developer/Organization: Google Research         •	Model Architecture: Convolutional Neural Network (CNN)         •	Key Features: Achieves state-of-the-art performance with fewer parameters and computations.         •	Performance Metrics: Achieved state-of-the-art results on ImageNet classification tasks.         •	Availability: Open-source (licensed under Apache License 2.0)         Google research blog: https://blog.research.google/2019/05/efficientnet-improving-accuracy-and.html?m=1         Github: https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/README.md         \r\n \r\n"},{"slug":"T5","title":"Text-To-Text Transfer Transformer","excerpt":"General-purpose text-to-text transformer model developed by Google AI Language Team","image":"T5.png","isFeatured":false,"readerCount":"1.7k","date":"2022-12-30","content":"\r\n         •	Model Description: General-purpose text-to-text transformer model.         •	Model Developer/Organization: Google AI Language Team         •	Model Architecture: Transformer         •	Key Features: Unified framework for various NLP tasks by framing them as text-to-text transformations.         •	Pe•	Model Category: Natural Language Processing (NLP)         rformance Metrics: Achieved state-of-the-art results in several NLP benchmarks.         •	Availability: Open-source (licensed under Apache License 2.0)         Github blog: https://github.com/google-research/text-to-text-transfer-transformer         Google research blog: http://blog.research.google/2020/02/exploring-transfer-learning-with-t5.html         \r\n \r\n"},{"slug":"DALL-E","title":"Generates images from textual descriptions using a conditional version of GPT.","excerpt":"Generates diverse and creative images based on textual prompts.","image":"DALL-E.png","isFeatured":true,"readerCount":"3.4k","date":"2022-12-30","content":"\r\n         •	Model Description: Generates images from textual descriptions using a conditional version of GPT.         •	Model Category: Natural Language Processing (NLP) for Image Generation         •	Model Developer/Organization: OpenAI         •	Model Architecture: Transformer         •	Key Features: Generates diverse and creative images based on textual prompts.         •	Performance Metrics: Notable for its capability to generate high-quality images from textual descriptions.         •	Availability: Proprietary (API access provided by OpenAI)         Wikipedia: https://en.wikipedia.org/wiki/DALL-E         Microsoft blog: https://create.microsoft.com/en-us/learn/articles/how-to-image-prompts-dall-e-ai         \r\n \r\n"},{"slug":"CycleGAN","title":"Cycle-Consistent Generative Adversarial Network","excerpt":"Generates diverse and creative images based on textual prompts.","image":"CycleGAN.png","isFeatured":false,"readerCount":"1.3k","date":"2022-12-30","content":"\r\n         •	Model Description: Unsupervised image-to-image translation model.         •	Model Category: Computer Vision         •	Model Developer/Organization: Jun-Yan Zhu et al. (UC Berkeley)         •	Model Architecture: Generative Adversarial Network (GAN)         •	Key Features: Translates images from one domain to another without paired examples using a cycle-consistency loss.         •	Performance Metrics: Demonstrated impressive results in various image translation tasks.         •	Availability: Open-source (licensed under MIT License)         Tensorflow website: https://www.tensorflow.org/tutorials/generative/cyclegan         Geeksforgeeks: https://www.geeksforgeeks.org/cycle-generative-adversarial-network-cyclegan-2/                 \r\n \r\n"},{"slug":"VGG","title":"Visual Geometry Group","excerpt":"Deep convolutional neural network architecture for image recognition.","image":"VGG.png","isFeatured":true,"readerCount":"2.7k","date":"2022-12-30","content":"\r\n         •	Model Description: Deep convolutional neural network architecture for image recognition.         •	Model Category: Computer Vision         •	Model Developer/Organization: Visual Geometry Group, University of Oxford         •	Model Architecture: Convolutional Neural Network (CNN)         •	Key Features: Known for its simplicity and effectiveness in image classification tasks.         •	Performance Metrics: Achieved competitive results in ImageNet classification challenges.         •	Availability: Open-source (licensed under Creative Commons Attribution 4.0 International License)         Geeksforgeeks: https://www.geeksforgeeks.org/vgg-16-cnn-model/         Kaggle: https://www.kaggle.com/code/blurredmachine/vggnet-16-architecture-a-complete-guide         \r\n \r\n"},{"slug":"DenseNet","title":"Densely Connected Convolutional Network","excerpt":"Dense connectivity patterns between layers in convolutional neural networks.","image":"DenseNet.png","isFeatured":false,"readerCount":"2.4k","date":"2022-12-30","content":"\r\n         •	Model Description: Dense connectivity patterns between layers in convolutional neural networks.         •	Model Category: Computer Vision         •	Model Developer/Organization: Cornell University         •	Model Architecture: Convolutional Neural Network (CNN)         •	Key Features: Facilitates feature reuse and alleviates the vanishing-gradient problem.         •	Performance Metrics: Achieved state-of-the-art results in image classification and object detection tasks.         •	Availability: Open-source (licensed under MIT License)         Github blog: https://amaarora.github.io/posts/2020-08-02-densenets.html         Microsoft Learn: https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/densenet?view=azureml-api-2         \r\n \r\n"},{"slug":"BART","title":"Bidirectional and Auto-Regressive Transformers","excerpt":"Sequence-to-sequence model for text generation and comprehension tasks.","image":"BART.png","isFeatured":false,"readerCount":"2.7k","date":"2022-12-30","content":"\r\n         •	Model Description: Sequence-to-sequence model for text generation and comprehension tasks.         •	Model Category: Natural Language Processing (NLP)         •	Model Developer/Organization: Facebook AI         •	Model Architecture: Transformer         •	Key Features: Capable of various NLP tasks, including text summarization, language translation, and document completion.         •	Performance Metrics: Achieved competitive results in summarization and generation benchmarks.         •	Availability: Open-source (licensed under Apache License 2.0)         Google blogs: https://blog.google/technology/ai/bard-google-ai-search-updates/         \r\n \r\n"},{"slug":"RoBERTa ","title":"Robustly Optimized BERT Approach","excerpt":"Optimized version of BERT with improved training procedures.","image":"RoBERTa.png","isFeatured":true,"readerCount":"3.3k","date":"2022-12-30","content":"\r\n         •	Model Description: Optimized version of BERT with improved training procedures.         •	Model Category: Natural Language Processing (NLP)         •	Model Developer/Organization: Facebook AI         •	Model Architecture: Transformer         •	Key Features: Achieves better performance by pre-training with larger datasets and longer sequences.         •	Performance Metrics: Competitive results in various NLP benchmarks, including GLUE and SQuAD.         •	Availability: Open-source (licensed under Apache License 2.0)         Geeksforgeeks: https://www.geeksforgeeks.org/overview-of-roberta-model/         Pytorch: https://pytorch.org/hub/pytorch_fairseq_roberta/         \r\n \r\n"},{"slug":"EfficientDet","title":"Developed by Google Research Team","excerpt":"Achieves state-of-the-art performance with fewer parameters and computations in object detection tasks.","image":"EfficientDet.png","isFeatured":false,"readerCount":"2.3k","date":"2022-12-30","content":"\r\n         •	Model Description: Scalable and efficient object detection model based on the EfficientNet architecture.         •	Model Category: Computer Vision         •	Model Developer/Organization: Google Research         •	Model Architecture: Convolutional Neural Network (CNN)         •	Key Features: Achieves state-of-the-art performance with fewer parameters and computations in object detection tasks.         •	Performance Metrics: Demonstrated superior performance compared to previous object detection models.         •	Availability: Open-source (licensed under Apache License 2.0)         Wikipedia: https://en.wikipedia.org/wiki/Vision_transformer         Google research blog: https://blog.research.google/2019/05/efficientnet-improving-accuracy-and.html?m=1                 \r\n \r\n"},{"slug":"Mask R-CNN ","title":"Region-based Convolutional Neural Network","excerpt":"Extends Faster R-CNN by adding a branch for predicting segmentation masks.","image":"Mask.png","isFeatured":false,"readerCount":"1.5k","date":"2022-12-30","content":"\r\n         •	Model Description: Extends Faster R-CNN by adding a branch for predicting segmentation masks.         •	Model Category: Computer Vision         •	Model Developer/Organization: Facebook AI Research         •	Model Architecture: Convolutional Neural Network (CNN)         •	Key Features: Simultaneously predicts object bounding boxes and segmentation masks.         •	Performance Metrics: Achieved state-of-the-art results in instance segmentation tasks.         •	Availability: Open-source (licensed under MIT License)         Geeksfoegeeks: https://www.geeksforgeeks.org/mask-r-cnn-ml/         research blog: https://paperswithcode.com/paper/mask-r-cnn                  \r\n \r\n"}]
}
